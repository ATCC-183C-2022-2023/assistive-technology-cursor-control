{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import cv2\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE_TYPES = 11\n",
    "LABEL_DICT = {k:i for i,k in enumerate([21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33])}\n",
    "CONNECTION_LABELS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (5, 6), (6, 7), (7, 8),\n",
    "    (9, 10), (10, 11), (11, 12),\n",
    "    (13, 14), (14, 15), (15, 16),\n",
    "    (17, 18), (18, 19), (19, 20),\n",
    "    (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_path='gesture_recognition/Fall 2020/data_rotated', sequence_length=5):\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "    for subjectName in os.listdir(data_path):\n",
    "        if not (subjectName.startswith(\"Subject\") or subjectName.startswith(\"subject\")): continue\n",
    "        # subjectNum = int(re.findall(r'(\\d+)', subjectName)[0])\n",
    "        for sceneName in os.listdir(os.path.join(data_path, subjectName)):\n",
    "            if not (sceneName.startswith(\"Scene\") or subjectName.startswith(\"scene\")): continue\n",
    "            for groupEntry in os.scandir(os.path.join(data_path, subjectName, sceneName)):\n",
    "                with open(groupEntry, 'r') as f:\n",
    "                    groupData = json.load(f)\n",
    "                    for gesture in groupData:\n",
    "                        # print(gesture['label'], gesture['keypoints'])\n",
    "                        for i in range(len(gesture['keypoints'])):\n",
    "                            if not gesture['keypoints'][i]:\n",
    "                                gesture['keypoints'][i] = [[np.nan, np.nan, np.nan] for _ in range(21)]\n",
    "                        for start_frame in range(len(gesture['keypoints']) - sequence_length + 1):\n",
    "                            keypoints.append(gesture['keypoints'][start_frame: start_frame + sequence_length])\n",
    "                            labels.append(LABEL_DICT[gesture['label']])\n",
    "    keypoints = np.array(keypoints)\n",
    "    labels = np.array(labels)\n",
    "    return keypoints, labels\n",
    "keypoints, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_connection_angles(keypoints, sequence_length=5, keypoints_num=21, keypoints_dimensions=3):\n",
    "    connections = []\n",
    "    for connection in CONNECTION_LABELS:\n",
    "        connections.append(keypoints[..., connection[1], :] - keypoints[..., connection[0], :])\n",
    "    connections = np.stack(connections, axis = -2)\n",
    "    tensor1 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,2,4,3)\n",
    "    tensor2 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,4,2,3)\n",
    "    angles = (tensor1*tensor2).sum(axis=-1)/np.linalg.norm(tensor1,axis=-1)/np.linalg.norm(tensor2,axis=-1)\n",
    "    angles = angles.transpose(2,3,0,1)[np.triu_indices(21, k = 1)].transpose(1,2,0)\n",
    "    return np.arccos(angles)\n",
    "angles = generate_connection_angles(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(keypoints):\n",
    "    for sequence in keypoints:\n",
    "        for points in sequence:\n",
    "            img = np.zeros((256, 256, 3))\n",
    "            for point in points:\n",
    "                x, y, z = point\n",
    "                if np.isnan(x):\n",
    "                    continue\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (255, 0, 0), 2)\n",
    "            for connection in CONNECTION_LABELS:\n",
    "                if np.isnan(points[connection[1]][0]):\n",
    "                    continue\n",
    "                x0, y0, z0 = points[connection[0]]\n",
    "                x1, y1, z1 = points[connection[1]]\n",
    "                cv2.line(img, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Key Points\", img)\n",
    "            key = cv2.waitKey(100)\n",
    "            if key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(1) # cannot close window on macOS without this line\n",
    "                return\n",
    "visualize_keypoints(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(keypoints, angles):\n",
    "    data_length = keypoints.shape[0]\n",
    "    sequence_length = keypoints.shape[1]\n",
    "    keypoints = keypoints.reshape(data_length*sequence_length, -1)\n",
    "    angles = angles.reshape(data_length*sequence_length, -1)\n",
    "    features = np.concatenate((keypoints, angles), -1)\n",
    "    df = pd.DataFrame(features)\n",
    "    df = (df-df.mean())/df.std()\n",
    "    df = df.fillna(0)\n",
    "    features = df.to_numpy().reshape(data_length, sequence_length, -1)\n",
    "    return features\n",
    "X = process_features(keypoints, angles)\n",
    "#normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "#normalizer.adapt(X)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(processed_keypoints, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 1.2533 - accuracy: 0.7077 - val_loss: 1.0325 - val_accuracy: 0.7610\n",
      "Epoch 2/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.7463 - accuracy: 0.8272 - val_loss: 0.8730 - val_accuracy: 0.7797\n",
      "Epoch 3/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.8501 - val_loss: 0.8646 - val_accuracy: 0.7887\n",
      "Epoch 4/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.8599 - val_loss: 0.7887 - val_accuracy: 0.8017\n",
      "Epoch 5/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8697 - val_loss: 0.7034 - val_accuracy: 0.8135\n",
      "Epoch 6/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8794 - val_loss: 0.7696 - val_accuracy: 0.8064\n",
      "Epoch 7/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8854 - val_loss: 0.7842 - val_accuracy: 0.8092\n",
      "Epoch 8/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8863 - val_loss: 0.8024 - val_accuracy: 0.8011\n",
      "Epoch 9/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8929 - val_loss: 0.7741 - val_accuracy: 0.8060\n",
      "Epoch 10/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.8954 - val_loss: 0.7295 - val_accuracy: 0.8126\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tf.keras.Sequential([tf.keras.layers.LSTM(GESTURE_TYPES, activation=None), tf.keras.layers.Activation('sigmoid')])\n",
    "model_lstm.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics='accuracy')\n",
    "history = model_lstm.fit(X, labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 1.5480 - accuracy: 0.4291 - val_loss: 1.4615 - val_accuracy: 0.4497\n",
      "Epoch 2/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 1.2213 - accuracy: 0.5324 - val_loss: 1.1742 - val_accuracy: 0.5542\n",
      "Epoch 3/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.7941 - accuracy: 0.7020 - val_loss: 0.7767 - val_accuracy: 0.7565\n",
      "Epoch 4/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5794 - accuracy: 0.8158 - val_loss: 0.7348 - val_accuracy: 0.7794\n",
      "Epoch 5/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.8344 - val_loss: 0.7164 - val_accuracy: 0.7820\n",
      "Epoch 6/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5036 - accuracy: 0.8429 - val_loss: 0.7016 - val_accuracy: 0.7946\n",
      "Epoch 7/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4866 - accuracy: 0.8471 - val_loss: 0.7167 - val_accuracy: 0.7906\n",
      "Epoch 8/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4702 - accuracy: 0.8502 - val_loss: 0.7290 - val_accuracy: 0.7887\n",
      "Epoch 9/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4615 - accuracy: 0.8549 - val_loss: 0.6709 - val_accuracy: 0.8004\n",
      "Epoch 10/10\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4470 - accuracy: 0.8595 - val_loss: 0.6886 - val_accuracy: 0.7955\n"
     ]
    }
   ],
   "source": [
    "model_rnn = tf.keras.Sequential([tf.keras.layers.SimpleRNN(GESTURE_TYPES, activation=None), tf.keras.layers.Activation('sigmoid')])\n",
    "model_rnn.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics='accuracy')\n",
    "history = model_rnn.fit(X, labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 1.2720 - accuracy: 0.7391 - val_loss: 0.9133 - val_accuracy: 0.7606\n",
      "Epoch 2/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.5956 - accuracy: 0.8321 - val_loss: 0.7756 - val_accuracy: 0.7807\n",
      "Epoch 3/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.4809 - accuracy: 0.8533 - val_loss: 0.8177 - val_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.4291 - accuracy: 0.8651 - val_loss: 0.7420 - val_accuracy: 0.7970\n",
      "Epoch 5/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3947 - accuracy: 0.8756 - val_loss: 0.7351 - val_accuracy: 0.8015\n",
      "Epoch 6/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3607 - accuracy: 0.8832 - val_loss: 0.6908 - val_accuracy: 0.8075\n",
      "Epoch 7/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3441 - accuracy: 0.8895 - val_loss: 0.7397 - val_accuracy: 0.8109\n",
      "Epoch 8/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3304 - accuracy: 0.8919 - val_loss: 0.7210 - val_accuracy: 0.8099\n",
      "Epoch 9/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3155 - accuracy: 0.8959 - val_loss: 0.7161 - val_accuracy: 0.8137\n",
      "Epoch 10/10\n",
      "584/584 [==============================] - 2s 3ms/step - loss: 0.3039 - accuracy: 0.8986 - val_loss: 0.7537 - val_accuracy: 0.8107\n"
     ]
    }
   ],
   "source": [
    "model_lstm2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(GESTURE_TYPES, activation=None)), tf.keras.layers.Activation('sigmoid')\n",
    "])\n",
    "model_lstm2.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics='accuracy')\n",
    "history = model_lstm2.fit(X, labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.5487 - accuracy: 0.8484 - val_loss: 0.5405 - val_accuracy: 0.8240\n",
      "Epoch 2/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.2247 - accuracy: 0.9302 - val_loss: 0.5660 - val_accuracy: 0.8272\n",
      "Epoch 3/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.1336 - accuracy: 0.9650 - val_loss: 0.5931 - val_accuracy: 0.8285\n",
      "Epoch 4/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0815 - accuracy: 0.9810 - val_loss: 0.6285 - val_accuracy: 0.8156\n",
      "Epoch 5/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0551 - accuracy: 0.9877 - val_loss: 0.6726 - val_accuracy: 0.8206\n",
      "Epoch 6/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0368 - accuracy: 0.9925 - val_loss: 0.6749 - val_accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9945 - val_loss: 0.7246 - val_accuracy: 0.8263\n",
      "Epoch 8/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.7177 - val_accuracy: 0.8178\n",
      "Epoch 9/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.7309 - val_accuracy: 0.8208\n",
      "Epoch 10/10\n",
      "584/584 [==============================] - 2s 4ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.7509 - val_accuracy: 0.8233\n"
     ]
    }
   ],
   "source": [
    "model_lstm4 = tf.keras.Sequential([tf.keras.layers.LSTM(128), layers.Dense(GESTURE_TYPES), layers.Activation('sigmoid')])\n",
    "model_lstm4.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics='accuracy')\n",
    "history = model_lstm4.fit(X, labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
