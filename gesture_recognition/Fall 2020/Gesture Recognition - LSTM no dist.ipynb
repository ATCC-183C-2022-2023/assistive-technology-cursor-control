{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import cv2\n",
    "import sklearn\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE_TYPES = 11\n",
    "LABEL_DICT = {k:i for i,k in enumerate([21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33])}\n",
    "CONNECTION_LABELS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (5, 6), (6, 7), (7, 8),\n",
    "    (9, 10), (10, 11), (11, 12),\n",
    "    (13, 14), (14, 15), (15, 16),\n",
    "    (17, 18), (18, 19), (19, 20),\n",
    "    (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23346, 5, 21, 3) (23346,)\n"
     ]
    }
   ],
   "source": [
    "def load_keypoint_sequences(data_path='gesture_recognition/Fall 2020/data', sequence_length=5):\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "    for subjectName in os.listdir(data_path):\n",
    "        if not (subjectName.startswith(\"Subject\") or subjectName.startswith(\"subject\")): continue\n",
    "        # subjectNum = int(re.findall(r'(\\d+)', subjectName)[0])\n",
    "        for sceneName in os.listdir(os.path.join(data_path, subjectName)):\n",
    "            if not (sceneName.startswith(\"Scene\") or subjectName.startswith(\"scene\")): continue\n",
    "            for groupEntry in os.scandir(os.path.join(data_path, subjectName, sceneName)):\n",
    "                with open(groupEntry, 'r') as f:\n",
    "                    groupData = json.load(f)\n",
    "                    for gesture in groupData:\n",
    "                        # print(gesture['label'], gesture['keypoints'])\n",
    "                        for i in range(len(gesture['keypoints'])):\n",
    "                            if not gesture['keypoints'][i]:\n",
    "                                gesture['keypoints'][i] = [[np.nan, np.nan, np.nan] for _ in range(21)]\n",
    "                        for start_frame in range(len(gesture['keypoints']) - sequence_length + 1):\n",
    "                            keypoints.append(gesture['keypoints'][start_frame: start_frame + sequence_length])\n",
    "                            labels.append(LABEL_DICT[gesture['label']])\n",
    "    keypoints = np.array(keypoints)\n",
    "    labels = np.array(labels)\n",
    "    return keypoints, labels\n",
    "keypoints, labels = load_keypoint_sequences()\n",
    "print(keypoints.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23346, 5, 210)\n"
     ]
    }
   ],
   "source": [
    "def generate_connection_angles_from_sequences(keypoints, keypoints_num=21, keypoints_dimensions=3):\n",
    "    connections = []\n",
    "    for connection in CONNECTION_LABELS:\n",
    "        connections.append(keypoints[..., connection[1], :] - keypoints[..., connection[0], :])\n",
    "    connections = np.stack(connections, axis = -2)\n",
    "    tensor1 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,2,4,3)\n",
    "    tensor2 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,4,2,3)\n",
    "    angles = (tensor1*tensor2).sum(axis=-1)/np.linalg.norm(tensor1,axis=-1)/np.linalg.norm(tensor2,axis=-1)\n",
    "    angles = angles.transpose(2,3,0,1)[np.triu_indices(21, k = 1)].transpose(1,2,0)\n",
    "    return np.arccos(angles)\n",
    "angles = generate_connection_angles_from_sequences(keypoints)\n",
    "print(angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23346, 5, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "def generate_joint_distances_from_sequences(keypoints, keypoints_num=21, keypoints_dimensions=3):\n",
    "    connections = []\n",
    "    for connection in CONNECTION_LABELS:\n",
    "        connections.append(keypoints[..., connection[1], :] - keypoints[..., connection[0], :])\n",
    "    connections = np.stack(connections, axis = -2)\n",
    "    tensor1 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,2,4,3)\n",
    "    tensor2 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,4,2,3)\n",
    "    distances = np.linalg.norm(tensor1-tensor2,axis=-1)\n",
    "    return distances\n",
    "distances = generate_joint_distances_from_sequences(keypoints)\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoint_sequences(keypoints):\n",
    "    for sequence in keypoints:\n",
    "        for points in sequence:\n",
    "            img = np.zeros((480, 640, 3))\n",
    "            for point in points:\n",
    "                x, y, z = point\n",
    "                if np.isnan(x):\n",
    "                    continue\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (255, 0, 0), 2)\n",
    "            for connection in CONNECTION_LABELS:\n",
    "                if np.isnan(points[connection[0]][0]):\n",
    "                    continue\n",
    "                x0, y0, z0 = points[connection[0]]\n",
    "                x1, y1, z1 = points[connection[1]]\n",
    "                cv2.line(img, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Key Points\", img)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(1) # cannot close window on macOS without this line\n",
    "                return\n",
    "# visualize_keypoint_sequences(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23346, 5, 273)\n"
     ]
    }
   ],
   "source": [
    "def process_sequence_features(keypoints, angles):\n",
    "    data_length = keypoints.shape[0]\n",
    "    sequence_length = keypoints.shape[1]\n",
    "    keypoints = keypoints.reshape(data_length*sequence_length, -1)\n",
    "    angles = angles.reshape(data_length*sequence_length, -1)\n",
    "    features = np.concatenate((keypoints, angles), -1)\n",
    "    df = pd.DataFrame(features)\n",
    "    df = (df-df.mean())/df.std()\n",
    "    df = df.fillna(0)\n",
    "    features = df.to_numpy().reshape(data_length, sequence_length, -1)\n",
    "    return features\n",
    "X = process_sequence_features(keypoints, angles)\n",
    "#normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "#normalizer.adapt(X)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(processed_keypoints, labels, test_size=0.2, random_state=0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 17s 920us/sample - loss: 0.7352 - accuracy: 0.7601 - val_loss: 0.6725 - val_accuracy: 0.7884\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 12s 663us/sample - loss: 0.4159 - accuracy: 0.8669 - val_loss: 0.6619 - val_accuracy: 0.8024\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 10s 512us/sample - loss: 0.3599 - accuracy: 0.8847 - val_loss: 0.6740 - val_accuracy: 0.8118\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 12s 622us/sample - loss: 0.3272 - accuracy: 0.8958 - val_loss: 0.6572 - val_accuracy: 0.8146\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 13s 677us/sample - loss: 0.2934 - accuracy: 0.9059 - val_loss: 0.6391 - val_accuracy: 0.8218\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 12s 639us/sample - loss: 0.2777 - accuracy: 0.9105 - val_loss: 0.6755 - val_accuracy: 0.8161\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 13s 669us/sample - loss: 0.2621 - accuracy: 0.9156 - val_loss: 0.6964 - val_accuracy: 0.8156\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 13s 680us/sample - loss: 0.2532 - accuracy: 0.9203 - val_loss: 0.7003 - val_accuracy: 0.8122\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 12s 661us/sample - loss: 0.2354 - accuracy: 0.9233 - val_loss: 0.7605 - val_accuracy: 0.8135\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 12s 659us/sample - loss: 0.2218 - accuracy: 0.9270 - val_loss: 0.7305 - val_accuracy: 0.8128\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 13s 683us/sample - loss: 0.2327 - accuracy: 0.9256 - val_loss: 0.7228 - val_accuracy: 0.8214\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 13s 677us/sample - loss: 0.2036 - accuracy: 0.9332 - val_loss: 0.7998 - val_accuracy: 0.8118\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 13s 694us/sample - loss: 0.1984 - accuracy: 0.9362 - val_loss: 0.7660 - val_accuracy: 0.8171\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 14s 735us/sample - loss: 0.1945 - accuracy: 0.9363 - val_loss: 0.8173 - val_accuracy: 0.8193\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 12s 639us/sample - loss: 0.1884 - accuracy: 0.9380 - val_loss: 0.8358 - val_accuracy: 0.8118\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 12s 652us/sample - loss: 0.1818 - accuracy: 0.9424 - val_loss: 0.8617 - val_accuracy: 0.8116\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 12s 653us/sample - loss: 0.1747 - accuracy: 0.9438 - val_loss: 0.8777 - val_accuracy: 0.8077\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 13s 678us/sample - loss: 0.1677 - accuracy: 0.9468 - val_loss: 0.9485 - val_accuracy: 0.8019\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 12s 665us/sample - loss: 0.1720 - accuracy: 0.9443 - val_loss: 0.8611 - val_accuracy: 0.8128\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 12s 667us/sample - loss: 0.1588 - accuracy: 0.9483 - val_loss: 0.8993 - val_accuracy: 0.8158\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tf.keras.Sequential([layers.Masking(), layers.LSTM(GESTURE_TYPES, activation=None), layers.Activation('softmax')])\n",
    "model_lstm.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_lstm.fit(X, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 31s 2ms/sample - loss: 0.7706 - accuracy: 0.7711 - val_loss: 0.7010 - val_accuracy: 0.7906\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 16s 881us/sample - loss: 0.4198 - accuracy: 0.8658 - val_loss: 0.6489 - val_accuracy: 0.8051\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.3717 - accuracy: 0.8809 - val_loss: 0.6710 - val_accuracy: 0.8019\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.3305 - accuracy: 0.8931 - val_loss: 0.6538 - val_accuracy: 0.8062\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.3045 - accuracy: 0.9004 - val_loss: 0.6926 - val_accuracy: 0.8069\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.2811 - accuracy: 0.9088 - val_loss: 0.6681 - val_accuracy: 0.8131\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.2670 - accuracy: 0.9134 - val_loss: 0.7028 - val_accuracy: 0.8009\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.2488 - accuracy: 0.9202 - val_loss: 0.7136 - val_accuracy: 0.8143\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.2337 - accuracy: 0.9243 - val_loss: 0.7096 - val_accuracy: 0.8169\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.2248 - accuracy: 0.9261 - val_loss: 0.7271 - val_accuracy: 0.8161\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.2218 - accuracy: 0.9263 - val_loss: 0.7443 - val_accuracy: 0.8165\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.2079 - accuracy: 0.9331 - val_loss: 0.7957 - val_accuracy: 0.8126\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.2029 - accuracy: 0.9334 - val_loss: 0.7918 - val_accuracy: 0.8113\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.1939 - accuracy: 0.9361 - val_loss: 0.7822 - val_accuracy: 0.8122\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.1906 - accuracy: 0.9398 - val_loss: 0.8278 - val_accuracy: 0.8116\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.1779 - accuracy: 0.9424 - val_loss: 0.8285 - val_accuracy: 0.8146\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.1817 - accuracy: 0.9415 - val_loss: 0.9323 - val_accuracy: 0.8066\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.1740 - accuracy: 0.9435 - val_loss: 0.8394 - val_accuracy: 0.8096\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.1688 - accuracy: 0.9462 - val_loss: 0.8521 - val_accuracy: 0.8075\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 19s 999us/sample - loss: 0.1642 - accuracy: 0.9468 - val_loss: 0.9107 - val_accuracy: 0.8062\n"
     ]
    }
   ],
   "source": [
    "model_bilstm = tf.keras.Sequential([layers.Masking(), layers.Bidirectional(layers.LSTM(GESTURE_TYPES, activation=None)), layers.Activation('softmax')])\n",
    "model_bilstm.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_bilstm.fit(X, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making LSTM bidirectional does not improve the accuracy by a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 10s 509us/sample - loss: 1.1371 - accuracy: 0.6599 - val_loss: 0.8616 - val_accuracy: 0.7343\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 6s 305us/sample - loss: 0.6330 - accuracy: 0.8057 - val_loss: 0.7836 - val_accuracy: 0.7608\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 6s 331us/sample - loss: 0.5504 - accuracy: 0.8266 - val_loss: 0.7540 - val_accuracy: 0.7681\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 6s 317us/sample - loss: 0.5152 - accuracy: 0.8398 - val_loss: 0.7375 - val_accuracy: 0.7715\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 6s 332us/sample - loss: 0.4830 - accuracy: 0.8483 - val_loss: 0.6947 - val_accuracy: 0.7850\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 6s 333us/sample - loss: 0.4708 - accuracy: 0.8520 - val_loss: 0.7107 - val_accuracy: 0.7809\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 6s 330us/sample - loss: 0.4476 - accuracy: 0.8594 - val_loss: 0.6730 - val_accuracy: 0.7901\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 6s 331us/sample - loss: 0.4328 - accuracy: 0.8646 - val_loss: 0.6898 - val_accuracy: 0.7908\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 6s 334us/sample - loss: 0.4199 - accuracy: 0.8688 - val_loss: 0.6811 - val_accuracy: 0.7927\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 6s 331us/sample - loss: 0.4081 - accuracy: 0.8726 - val_loss: 0.7092 - val_accuracy: 0.7880\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 6s 345us/sample - loss: 0.3986 - accuracy: 0.8727 - val_loss: 0.6431 - val_accuracy: 0.8019\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 6s 327us/sample - loss: 0.3901 - accuracy: 0.8787 - val_loss: 0.6939 - val_accuracy: 0.7970\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 6s 314us/sample - loss: 0.3846 - accuracy: 0.8780 - val_loss: 0.6527 - val_accuracy: 0.8049\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 6s 332us/sample - loss: 0.3749 - accuracy: 0.8813 - val_loss: 0.6644 - val_accuracy: 0.8041\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 6s 336us/sample - loss: 0.3704 - accuracy: 0.8798 - val_loss: 0.6535 - val_accuracy: 0.8060\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 6s 331us/sample - loss: 0.3627 - accuracy: 0.8846 - val_loss: 0.6969 - val_accuracy: 0.7927\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 7s 355us/sample - loss: 0.3610 - accuracy: 0.8847 - val_loss: 0.6898 - val_accuracy: 0.7957\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 6s 346us/sample - loss: 0.3588 - accuracy: 0.8875 - val_loss: 0.6868 - val_accuracy: 0.8045\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 6s 333us/sample - loss: 0.3505 - accuracy: 0.8861 - val_loss: 0.7082 - val_accuracy: 0.8024\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 5s 284us/sample - loss: 0.3484 - accuracy: 0.8910 - val_loss: 0.7197 - val_accuracy: 0.7957\n"
     ]
    }
   ],
   "source": [
    "model_rnn = tf.keras.Sequential([layers.Masking(), layers.SimpleRNN(GESTURE_TYPES, activation=None), layers.Activation('softmax')])\n",
    "model_rnn.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_rnn.fit(X, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNN gives a slightly worse performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 26s 1ms/sample - loss: 0.4525 - accuracy: 0.8583 - val_loss: 0.5977 - val_accuracy: 0.8069\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.2183 - accuracy: 0.9324 - val_loss: 0.5826 - val_accuracy: 0.8169\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.1347 - accuracy: 0.9620 - val_loss: 0.6071 - val_accuracy: 0.8109\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0889 - accuracy: 0.9767 - val_loss: 0.6447 - val_accuracy: 0.8233\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0615 - accuracy: 0.9847 - val_loss: 0.6727 - val_accuracy: 0.8208\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0501 - accuracy: 0.9870 - val_loss: 0.6939 - val_accuracy: 0.8169\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0444 - accuracy: 0.9889 - val_loss: 0.7061 - val_accuracy: 0.8255\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.6916 - val_accuracy: 0.8285\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0302 - accuracy: 0.9930 - val_loss: 0.7480 - val_accuracy: 0.8229\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.8119 - val_accuracy: 0.8158\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0238 - accuracy: 0.9946 - val_loss: 0.7987 - val_accuracy: 0.8210\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.8382 - val_accuracy: 0.8188\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.8030 - val_accuracy: 0.8229\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.8392 - val_accuracy: 0.8184\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 19s 1ms/sample - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.8851 - val_accuracy: 0.8167\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.8553 - val_accuracy: 0.8221\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.9015 - val_accuracy: 0.8246\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 20s 1ms/sample - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.8781 - val_accuracy: 0.8238\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.9197 - val_accuracy: 0.8296\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 21s 1ms/sample - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.8978 - val_accuracy: 0.8199\n"
     ]
    }
   ],
   "source": [
    "model_lstm4 = tf.keras.Sequential([layers.Masking(), layers.LSTM(128), layers.Dense(GESTURE_TYPES), layers.Activation('softmax')])\n",
    "model_lstm4.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_lstm4.fit(X, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing depth may improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP on Concatenated Sequence of Data\n",
    "\n",
    "MLP generally has a worse performance than RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 4s 206us/sample - loss: 0.6502 - accuracy: 0.8016 - val_loss: 0.7110 - val_accuracy: 0.7908\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 2s 130us/sample - loss: 0.4873 - accuracy: 0.8508 - val_loss: 0.6974 - val_accuracy: 0.7953\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 2s 133us/sample - loss: 0.4520 - accuracy: 0.8600 - val_loss: 0.7138 - val_accuracy: 0.7972\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 3s 137us/sample - loss: 0.4281 - accuracy: 0.8677 - val_loss: 0.6949 - val_accuracy: 0.7979\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 3s 154us/sample - loss: 0.4088 - accuracy: 0.8711 - val_loss: 0.6887 - val_accuracy: 0.7985\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 3s 150us/sample - loss: 0.3994 - accuracy: 0.8740 - val_loss: 0.7386 - val_accuracy: 0.7946\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 3s 161us/sample - loss: 0.3866 - accuracy: 0.8773 - val_loss: 0.7093 - val_accuracy: 0.8009\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 3s 156us/sample - loss: 0.3754 - accuracy: 0.8820 - val_loss: 0.7502 - val_accuracy: 0.7944\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 2s 113us/sample - loss: 0.3646 - accuracy: 0.8836 - val_loss: 0.7180 - val_accuracy: 0.8009\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 2s 131us/sample - loss: 0.3576 - accuracy: 0.8856 - val_loss: 0.7263 - val_accuracy: 0.8009\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 3s 137us/sample - loss: 0.3513 - accuracy: 0.8872 - val_loss: 0.7200 - val_accuracy: 0.8056\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 3s 136us/sample - loss: 0.3432 - accuracy: 0.8894 - val_loss: 0.7425 - val_accuracy: 0.8002\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 3s 134us/sample - loss: 0.3380 - accuracy: 0.8929 - val_loss: 0.7331 - val_accuracy: 0.8041\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 3s 137us/sample - loss: 0.3352 - accuracy: 0.8936 - val_loss: 0.7441 - val_accuracy: 0.8002\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 2s 129us/sample - loss: 0.3279 - accuracy: 0.8955 - val_loss: 0.7501 - val_accuracy: 0.8101\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 2s 130us/sample - loss: 0.3233 - accuracy: 0.8962 - val_loss: 0.7326 - val_accuracy: 0.8024\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 2s 119us/sample - loss: 0.3193 - accuracy: 0.8960 - val_loss: 0.7672 - val_accuracy: 0.7957\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 3s 143us/sample - loss: 0.3178 - accuracy: 0.8951 - val_loss: 0.7591 - val_accuracy: 0.8043\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 3s 135us/sample - loss: 0.3079 - accuracy: 0.9000 - val_loss: 0.7849 - val_accuracy: 0.8024\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 2s 122us/sample - loss: 0.3100 - accuracy: 0.9006 - val_loss: 0.7990 - val_accuracy: 0.8094\n"
     ]
    }
   ],
   "source": [
    "X_expanded = X.reshape((X.shape[0],-1))\n",
    "model_mlp = tf.keras.Sequential([layers.Dense(GESTURE_TYPES), layers.Activation('softmax')])\n",
    "model_mlp.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_mlp.fit(X_expanded, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18676 samples, validate on 4670 samples\n",
      "Epoch 1/20\n",
      "18676/18676 [==============================] - 5s 246us/sample - loss: 0.9507 - accuracy: 0.7939 - val_loss: 0.8666 - val_accuracy: 0.7745\n",
      "Epoch 2/20\n",
      "18676/18676 [==============================] - 4s 198us/sample - loss: 0.5066 - accuracy: 0.8494 - val_loss: 0.7545 - val_accuracy: 0.7835\n",
      "Epoch 3/20\n",
      "18676/18676 [==============================] - 4s 193us/sample - loss: 0.4602 - accuracy: 0.8577 - val_loss: 0.6823 - val_accuracy: 0.7951\n",
      "Epoch 4/20\n",
      "18676/18676 [==============================] - 4s 193us/sample - loss: 0.4511 - accuracy: 0.8606 - val_loss: 0.7114 - val_accuracy: 0.7865\n",
      "Epoch 5/20\n",
      "18676/18676 [==============================] - 4s 194us/sample - loss: 0.4367 - accuracy: 0.8615 - val_loss: 0.7116 - val_accuracy: 0.7955\n",
      "Epoch 6/20\n",
      "18676/18676 [==============================] - 4s 204us/sample - loss: 0.4251 - accuracy: 0.8670 - val_loss: 0.7517 - val_accuracy: 0.7767\n",
      "Epoch 7/20\n",
      "18676/18676 [==============================] - 4s 203us/sample - loss: 0.4196 - accuracy: 0.8679 - val_loss: 0.7207 - val_accuracy: 0.7929\n",
      "Epoch 8/20\n",
      "18676/18676 [==============================] - 4s 208us/sample - loss: 0.4134 - accuracy: 0.8690 - val_loss: 0.7384 - val_accuracy: 0.7976\n",
      "Epoch 9/20\n",
      "18676/18676 [==============================] - 4s 205us/sample - loss: 0.4114 - accuracy: 0.8695 - val_loss: 0.6923 - val_accuracy: 0.7994\n",
      "Epoch 10/20\n",
      "18676/18676 [==============================] - 4s 192us/sample - loss: 0.3995 - accuracy: 0.8718 - val_loss: 0.7272 - val_accuracy: 0.7884\n",
      "Epoch 11/20\n",
      "18676/18676 [==============================] - 4s 213us/sample - loss: 0.3932 - accuracy: 0.8757 - val_loss: 0.7062 - val_accuracy: 0.8026\n",
      "Epoch 12/20\n",
      "18676/18676 [==============================] - 4s 197us/sample - loss: 0.3841 - accuracy: 0.8757 - val_loss: 0.7259 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "18676/18676 [==============================] - 4s 192us/sample - loss: 0.3791 - accuracy: 0.8789 - val_loss: 0.7124 - val_accuracy: 0.8021\n",
      "Epoch 14/20\n",
      "18676/18676 [==============================] - 5s 243us/sample - loss: 0.3704 - accuracy: 0.8815 - val_loss: 0.7857 - val_accuracy: 0.7979\n",
      "Epoch 15/20\n",
      "18676/18676 [==============================] - 5s 275us/sample - loss: 0.3723 - accuracy: 0.8818 - val_loss: 0.7213 - val_accuracy: 0.7979\n",
      "Epoch 16/20\n",
      "18676/18676 [==============================] - 5s 291us/sample - loss: 0.3643 - accuracy: 0.8856 - val_loss: 0.7737 - val_accuracy: 0.7863\n",
      "Epoch 17/20\n",
      "18676/18676 [==============================] - 5s 255us/sample - loss: 0.3566 - accuracy: 0.8869 - val_loss: 0.7465 - val_accuracy: 0.7987\n",
      "Epoch 18/20\n",
      "18676/18676 [==============================] - 5s 263us/sample - loss: 0.3560 - accuracy: 0.8846 - val_loss: 0.7353 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "18676/18676 [==============================] - 5s 255us/sample - loss: 0.3500 - accuracy: 0.8875 - val_loss: 0.7493 - val_accuracy: 0.8004\n",
      "Epoch 20/20\n",
      "18676/18676 [==============================] - 5s 243us/sample - loss: 0.3476 - accuracy: 0.8880 - val_loss: 0.8057 - val_accuracy: 0.7949\n"
     ]
    }
   ],
   "source": [
    "model_mlp2 = tf.keras.Sequential([layers.Dense(256), layers.Dense(GESTURE_TYPES), layers.Activation('softmax')])\n",
    "model_mlp2.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_mlp2.fit(X_expanded, labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
