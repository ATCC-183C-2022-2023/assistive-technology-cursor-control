{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import cv2\n",
    "import sklearn\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE_TYPES = 11\n",
    "LABEL_DICT = {k:i for i,k in enumerate([21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33])}\n",
    "CONNECTION_LABELS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (5, 6), (6, 7), (7, 8),\n",
    "    (9, 10), (10, 11), (11, 12),\n",
    "    (13, 14), (14, 15), (15, 16),\n",
    "    (17, 18), (18, 19), (19, 20),\n",
    "    (0, 5), (5, 9), (9, 13), (13, 17), (0, 17)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 21, 3) (98231,)\n"
     ]
    }
   ],
   "source": [
    "def load_keypoints(data_path='gesture_recognition/Fall 2020/data_30'):\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "    for subjectName in os.listdir(data_path):\n",
    "        if not (subjectName.startswith(\"Subject\") or subjectName.startswith(\"subject\")): continue\n",
    "        # subjectNum = int(re.findall(r'(\\d+)', subjectName)[0])\n",
    "        for sceneName in os.listdir(os.path.join(data_path, subjectName)):\n",
    "            if not (sceneName.startswith(\"Scene\") or subjectName.startswith(\"scene\")): continue\n",
    "            for groupEntry in os.scandir(os.path.join(data_path, subjectName, sceneName)):\n",
    "                with open(groupEntry, 'r') as f:\n",
    "                    groupData = json.load(f)\n",
    "                    for gesture in groupData:\n",
    "                        for i in range(len(gesture['keypoints'])):\n",
    "                            if not gesture['keypoints'][i]:\n",
    "                                continue\n",
    "                            keypoints.append(gesture['keypoints'][i])\n",
    "                            labels.append(LABEL_DICT[gesture['label']])\n",
    "    keypoints = np.array(keypoints)\n",
    "    labels = np.array(labels)\n",
    "    return keypoints, labels\n",
    "keypoints, labels = load_keypoints()\n",
    "print(keypoints.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 210)\n"
     ]
    }
   ],
   "source": [
    "def generate_connection_angles(keypoints, keypoints_num=21, keypoints_dimensions=3):\n",
    "    connections = []\n",
    "    for connection in CONNECTION_LABELS:\n",
    "        connections.append(keypoints[..., connection[1], :] - keypoints[..., connection[0], :])\n",
    "    connections = np.stack(connections, axis = -2)\n",
    "    tensor1 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,1,3,2)\n",
    "    tensor2 = connections[..., np.newaxis].repeat(keypoints_num, -1).transpose(0,3,1,2)\n",
    "    angles = (tensor1*tensor2).sum(axis=-1)/np.linalg.norm(tensor1,axis=-1)/np.linalg.norm(tensor2,axis=-1)\n",
    "    angles = angles.transpose(1,2,0)[np.triu_indices(21, k = 1)].transpose(1,0)\n",
    "    return np.arccos(angles)\n",
    "angles = generate_connection_angles(keypoints)\n",
    "print(angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(keypoints):\n",
    "    for points in keypoints:\n",
    "        img = np.zeros((480, 640, 3))\n",
    "        for point in points:\n",
    "            x, y, z = point\n",
    "            if not x:\n",
    "                continue\n",
    "            cv2.circle(img, (int(x), int(y)), 4, (255, 0, 0), 2)\n",
    "        for connection in CONNECTION_LABELS:\n",
    "            if not points[connection[0]][0]:\n",
    "                continue\n",
    "            x0, y0, z0 = points[connection[0]]\n",
    "            x1, y1, z1 = points[connection[1]]\n",
    "            cv2.line(img, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Key Points\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1) # cannot close window on macOS without this line\n",
    "            return\n",
    "# visualize_keypoints(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98231, 273)\n"
     ]
    }
   ],
   "source": [
    "def process_features(keypoints, angles):\n",
    "    data_length = keypoints.shape[0]\n",
    "    keypoints = keypoints.reshape(data_length, -1)\n",
    "    angles = angles.reshape(data_length, -1)\n",
    "    features = np.concatenate((keypoints, angles), -1)\n",
    "    df = pd.DataFrame(features)\n",
    "    df = (df-df.mean())/df.std()\n",
    "    df = df.fillna(0)\n",
    "    features = df.to_numpy().reshape(data_length, -1)\n",
    "    return features\n",
    "X = process_features(keypoints, angles)\n",
    "#normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "#normalizer.adapt(X)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(processed_keypoints, labels, test_size=0.2, random_state=0)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78584 samples, validate on 19647 samples\n",
      "Epoch 1/50\n",
      "78584/78584 [==============================] - 9s 108us/sample - loss: 1.1136 - accuracy: 0.6532 - val_loss: 1.1691 - val_accuracy: 0.6360\n",
      "Epoch 2/50\n",
      "78584/78584 [==============================] - 7s 95us/sample - loss: 1.0063 - accuracy: 0.6850 - val_loss: 1.1233 - val_accuracy: 0.6470\n",
      "Epoch 3/50\n",
      "78584/78584 [==============================] - 7s 90us/sample - loss: 0.9849 - accuracy: 0.6929 - val_loss: 1.1214 - val_accuracy: 0.6482\n",
      "Epoch 4/50\n",
      "78584/78584 [==============================] - 7s 90us/sample - loss: 0.9734 - accuracy: 0.6960 - val_loss: 1.1255 - val_accuracy: 0.6470\n",
      "Epoch 5/50\n",
      "78584/78584 [==============================] - 7s 89us/sample - loss: 0.9654 - accuracy: 0.6970 - val_loss: 1.1150 - val_accuracy: 0.6512\n",
      "Epoch 6/50\n",
      "78584/78584 [==============================] - 7s 91us/sample - loss: 0.9602 - accuracy: 0.6987 - val_loss: 1.1093 - val_accuracy: 0.6537\n",
      "Epoch 7/50\n",
      "78584/78584 [==============================] - 7s 92us/sample - loss: 0.9556 - accuracy: 0.7003 - val_loss: 1.1049 - val_accuracy: 0.6552\n",
      "Epoch 8/50\n",
      "78584/78584 [==============================] - 7s 94us/sample - loss: 0.9514 - accuracy: 0.7009 - val_loss: 1.1082 - val_accuracy: 0.6541\n",
      "Epoch 9/50\n",
      "78584/78584 [==============================] - 7s 93us/sample - loss: 0.9485 - accuracy: 0.7017 - val_loss: 1.1089 - val_accuracy: 0.6508\n",
      "Epoch 10/50\n",
      "78584/78584 [==============================] - 7s 90us/sample - loss: 0.9465 - accuracy: 0.7039 - val_loss: 1.0996 - val_accuracy: 0.6575\n",
      "Epoch 11/50\n",
      "78584/78584 [==============================] - 7s 90us/sample - loss: 0.9435 - accuracy: 0.7040 - val_loss: 1.0997 - val_accuracy: 0.6561\n",
      "Epoch 12/50\n",
      "78584/78584 [==============================] - 7s 92us/sample - loss: 0.9421 - accuracy: 0.7042 - val_loss: 1.1055 - val_accuracy: 0.6564\n",
      "Epoch 13/50\n",
      "78584/78584 [==============================] - 7s 92us/sample - loss: 0.9401 - accuracy: 0.7050 - val_loss: 1.0967 - val_accuracy: 0.6578\n",
      "Epoch 14/50\n",
      "78584/78584 [==============================] - 8s 96us/sample - loss: 0.9379 - accuracy: 0.7068 - val_loss: 1.0882 - val_accuracy: 0.6601\n",
      "Epoch 15/50\n",
      "78584/78584 [==============================] - 8s 102us/sample - loss: 0.9366 - accuracy: 0.7062 - val_loss: 1.0882 - val_accuracy: 0.6594\n",
      "Epoch 16/50\n",
      "78584/78584 [==============================] - 8s 103us/sample - loss: 0.9350 - accuracy: 0.7059 - val_loss: 1.0878 - val_accuracy: 0.6570\n",
      "Epoch 17/50\n",
      "78584/78584 [==============================] - 7s 95us/sample - loss: 0.9340 - accuracy: 0.7066 - val_loss: 1.0915 - val_accuracy: 0.6591\n",
      "Epoch 18/50\n",
      "78584/78584 [==============================] - 9s 115us/sample - loss: 0.9323 - accuracy: 0.7074 - val_loss: 1.0803 - val_accuracy: 0.6608\n",
      "Epoch 19/50\n",
      "78584/78584 [==============================] - 8s 104us/sample - loss: 0.9322 - accuracy: 0.7081 - val_loss: 1.0868 - val_accuracy: 0.6586\n",
      "Epoch 20/50\n",
      "78584/78584 [==============================] - 8s 104us/sample - loss: 0.9308 - accuracy: 0.7067 - val_loss: 1.0869 - val_accuracy: 0.6626\n",
      "Epoch 21/50\n",
      "78584/78584 [==============================] - 8s 107us/sample - loss: 0.9297 - accuracy: 0.7078 - val_loss: 1.0900 - val_accuracy: 0.6577\n",
      "Epoch 22/50\n",
      "78584/78584 [==============================] - 9s 112us/sample - loss: 0.9293 - accuracy: 0.7077 - val_loss: 1.1102 - val_accuracy: 0.6577\n",
      "Epoch 23/50\n",
      "78584/78584 [==============================] - 8s 107us/sample - loss: 0.9281 - accuracy: 0.7085 - val_loss: 1.0804 - val_accuracy: 0.6616\n",
      "Epoch 24/50\n",
      "78584/78584 [==============================] - 8s 104us/sample - loss: 0.9276 - accuracy: 0.7093 - val_loss: 1.0864 - val_accuracy: 0.6582\n",
      "Epoch 25/50\n",
      "78584/78584 [==============================] - 8s 101us/sample - loss: 0.9266 - accuracy: 0.7093 - val_loss: 1.0877 - val_accuracy: 0.6595\n",
      "Epoch 26/50\n",
      "78584/78584 [==============================] - 8s 100us/sample - loss: 0.9261 - accuracy: 0.7093 - val_loss: 1.0896 - val_accuracy: 0.6545\n",
      "Epoch 27/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9249 - accuracy: 0.7089 - val_loss: 1.0936 - val_accuracy: 0.6595\n",
      "Epoch 28/50\n",
      "78584/78584 [==============================] - 8s 97us/sample - loss: 0.9243 - accuracy: 0.7095 - val_loss: 1.0842 - val_accuracy: 0.6586\n",
      "Epoch 29/50\n",
      "78584/78584 [==============================] - 7s 94us/sample - loss: 0.9239 - accuracy: 0.7103 - val_loss: 1.0943 - val_accuracy: 0.6585\n",
      "Epoch 30/50\n",
      "78584/78584 [==============================] - 8s 97us/sample - loss: 0.9235 - accuracy: 0.7087 - val_loss: 1.0896 - val_accuracy: 0.6617\n",
      "Epoch 31/50\n",
      "78584/78584 [==============================] - 8s 98us/sample - loss: 0.9224 - accuracy: 0.7097 - val_loss: 1.0874 - val_accuracy: 0.6602\n",
      "Epoch 32/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9230 - accuracy: 0.7107 - val_loss: 1.0959 - val_accuracy: 0.6540\n",
      "Epoch 33/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9216 - accuracy: 0.7101 - val_loss: 1.0924 - val_accuracy: 0.6599\n",
      "Epoch 34/50\n",
      "78584/78584 [==============================] - 8s 100us/sample - loss: 0.9216 - accuracy: 0.7111 - val_loss: 1.0784 - val_accuracy: 0.6648\n",
      "Epoch 35/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9213 - accuracy: 0.7103 - val_loss: 1.0840 - val_accuracy: 0.6618\n",
      "Epoch 36/50\n",
      "78584/78584 [==============================] - 8s 102us/sample - loss: 0.9209 - accuracy: 0.7101 - val_loss: 1.0880 - val_accuracy: 0.6581\n",
      "Epoch 37/50\n",
      "78584/78584 [==============================] - 8s 103us/sample - loss: 0.9197 - accuracy: 0.7108 - val_loss: 1.0748 - val_accuracy: 0.6636\n",
      "Epoch 38/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9188 - accuracy: 0.7111 - val_loss: 1.0797 - val_accuracy: 0.6625\n",
      "Epoch 39/50\n",
      "78584/78584 [==============================] - 8s 98us/sample - loss: 0.9195 - accuracy: 0.7110 - val_loss: 1.0792 - val_accuracy: 0.6644\n",
      "Epoch 40/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9189 - accuracy: 0.7096 - val_loss: 1.0911 - val_accuracy: 0.6574\n",
      "Epoch 41/50\n",
      "78584/78584 [==============================] - 8s 99us/sample - loss: 0.9176 - accuracy: 0.7113 - val_loss: 1.0695 - val_accuracy: 0.6680\n",
      "Epoch 42/50\n",
      "78584/78584 [==============================] - 11s 144us/sample - loss: 0.9181 - accuracy: 0.7109 - val_loss: 1.0969 - val_accuracy: 0.6586\n",
      "Epoch 43/50\n",
      "78584/78584 [==============================] - 14s 174us/sample - loss: 0.9173 - accuracy: 0.7115 - val_loss: 1.0882 - val_accuracy: 0.6576\n",
      "Epoch 44/50\n",
      "78584/78584 [==============================] - 15s 186us/sample - loss: 0.9175 - accuracy: 0.7116 - val_loss: 1.0748 - val_accuracy: 0.6659\n",
      "Epoch 45/50\n",
      "78584/78584 [==============================] - 9s 119us/sample - loss: 0.9167 - accuracy: 0.7119 - val_loss: 1.0772 - val_accuracy: 0.6632\n",
      "Epoch 46/50\n",
      "78584/78584 [==============================] - 10s 123us/sample - loss: 0.9158 - accuracy: 0.7116 - val_loss: 1.0899 - val_accuracy: 0.6614\n",
      "Epoch 47/50\n",
      "78584/78584 [==============================] - 9s 113us/sample - loss: 0.9161 - accuracy: 0.7111 - val_loss: 1.0837 - val_accuracy: 0.6620\n",
      "Epoch 48/50\n",
      "78584/78584 [==============================] - 8s 107us/sample - loss: 0.9166 - accuracy: 0.7111 - val_loss: 1.0922 - val_accuracy: 0.6569\n",
      "Epoch 49/50\n",
      "78584/78584 [==============================] - 9s 115us/sample - loss: 0.9160 - accuracy: 0.7124 - val_loss: 1.0803 - val_accuracy: 0.6605\n",
      "Epoch 50/50\n",
      "78584/78584 [==============================] - 9s 110us/sample - loss: 0.9161 - accuracy: 0.7126 - val_loss: 1.0776 - val_accuracy: 0.6663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model_mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(GESTURE_TYPES, activation=None), \n",
    "    tf.keras.layers.Activation('softmax')])\n",
    "model_mlp.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_mlp.fit(X, labels, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78584 samples, validate on 19647 samples\n",
      "Epoch 1/30\n",
      "78584/78584 [==============================] - 15s 193us/sample - loss: 1.4260 - accuracy: 0.6366 - val_loss: 1.1789 - val_accuracy: 0.6372\n",
      "Epoch 2/30\n",
      "78584/78584 [==============================] - 14s 178us/sample - loss: 1.0219 - accuracy: 0.6814 - val_loss: 1.1364 - val_accuracy: 0.6446\n",
      "Epoch 3/30\n",
      "78584/78584 [==============================] - 14s 178us/sample - loss: 0.9925 - accuracy: 0.6891 - val_loss: 1.1193 - val_accuracy: 0.6515\n",
      "Epoch 4/30\n",
      "78584/78584 [==============================] - 14s 177us/sample - loss: 0.9769 - accuracy: 0.6943 - val_loss: 1.1196 - val_accuracy: 0.6521\n",
      "Epoch 5/30\n",
      "78584/78584 [==============================] - 14s 179us/sample - loss: 0.9676 - accuracy: 0.6983 - val_loss: 1.1120 - val_accuracy: 0.6526\n",
      "Epoch 6/30\n",
      "78584/78584 [==============================] - 14s 180us/sample - loss: 0.9605 - accuracy: 0.6990 - val_loss: 1.1062 - val_accuracy: 0.6540\n",
      "Epoch 7/30\n",
      "78584/78584 [==============================] - 15s 189us/sample - loss: 0.9552 - accuracy: 0.6999 - val_loss: 1.0921 - val_accuracy: 0.6571\n",
      "Epoch 8/30\n",
      "78584/78584 [==============================] - 14s 177us/sample - loss: 0.9520 - accuracy: 0.7009 - val_loss: 1.0991 - val_accuracy: 0.6599\n",
      "Epoch 9/30\n",
      "78584/78584 [==============================] - 14s 174us/sample - loss: 0.9482 - accuracy: 0.7026 - val_loss: 1.0930 - val_accuracy: 0.6538\n",
      "Epoch 10/30\n",
      "78584/78584 [==============================] - 14s 175us/sample - loss: 0.9457 - accuracy: 0.7039 - val_loss: 1.0950 - val_accuracy: 0.6570\n",
      "Epoch 11/30\n",
      "78584/78584 [==============================] - 14s 175us/sample - loss: 0.9431 - accuracy: 0.7044 - val_loss: 1.0805 - val_accuracy: 0.6590\n",
      "Epoch 12/30\n",
      "78584/78584 [==============================] - 14s 179us/sample - loss: 0.9400 - accuracy: 0.7049 - val_loss: 1.0870 - val_accuracy: 0.6607\n",
      "Epoch 13/30\n",
      "78584/78584 [==============================] - 14s 178us/sample - loss: 0.9380 - accuracy: 0.7060 - val_loss: 1.0878 - val_accuracy: 0.6596\n",
      "Epoch 14/30\n",
      "78584/78584 [==============================] - 14s 174us/sample - loss: 0.9369 - accuracy: 0.7056 - val_loss: 1.0884 - val_accuracy: 0.6575\n",
      "Epoch 15/30\n",
      "78584/78584 [==============================] - 14s 176us/sample - loss: 0.9359 - accuracy: 0.7059 - val_loss: 1.0926 - val_accuracy: 0.6527\n",
      "Epoch 16/30\n",
      "78584/78584 [==============================] - 14s 173us/sample - loss: 0.9337 - accuracy: 0.7061 - val_loss: 1.0809 - val_accuracy: 0.6603\n",
      "Epoch 17/30\n",
      "78584/78584 [==============================] - 14s 172us/sample - loss: 0.9324 - accuracy: 0.7068 - val_loss: 1.0874 - val_accuracy: 0.6592\n",
      "Epoch 18/30\n",
      "78584/78584 [==============================] - 13s 166us/sample - loss: 0.9314 - accuracy: 0.7072 - val_loss: 1.0832 - val_accuracy: 0.6608\n",
      "Epoch 19/30\n",
      "78584/78584 [==============================] - 13s 172us/sample - loss: 0.9304 - accuracy: 0.7073 - val_loss: 1.0868 - val_accuracy: 0.6570\n",
      "Epoch 20/30\n",
      "78584/78584 [==============================] - 13s 170us/sample - loss: 0.9291 - accuracy: 0.7069 - val_loss: 1.0804 - val_accuracy: 0.6628\n",
      "Epoch 21/30\n",
      "78584/78584 [==============================] - 13s 166us/sample - loss: 0.9276 - accuracy: 0.7080 - val_loss: 1.0921 - val_accuracy: 0.6587\n",
      "Epoch 22/30\n",
      "78584/78584 [==============================] - 13s 164us/sample - loss: 0.9271 - accuracy: 0.7083 - val_loss: 1.0861 - val_accuracy: 0.6591\n",
      "Epoch 23/30\n",
      "78584/78584 [==============================] - 13s 164us/sample - loss: 0.9260 - accuracy: 0.7087 - val_loss: 1.0766 - val_accuracy: 0.6603\n",
      "Epoch 24/30\n",
      "78584/78584 [==============================] - 13s 168us/sample - loss: 0.9257 - accuracy: 0.7098 - val_loss: 1.0839 - val_accuracy: 0.6589\n",
      "Epoch 25/30\n",
      "78584/78584 [==============================] - 13s 168us/sample - loss: 0.9252 - accuracy: 0.7082 - val_loss: 1.0798 - val_accuracy: 0.6620\n",
      "Epoch 26/30\n",
      "78584/78584 [==============================] - 13s 165us/sample - loss: 0.9244 - accuracy: 0.7088 - val_loss: 1.0833 - val_accuracy: 0.6606\n",
      "Epoch 27/30\n",
      "78584/78584 [==============================] - 13s 165us/sample - loss: 0.9231 - accuracy: 0.7091 - val_loss: 1.0796 - val_accuracy: 0.6596\n",
      "Epoch 28/30\n",
      "78584/78584 [==============================] - 14s 178us/sample - loss: 0.9223 - accuracy: 0.7088 - val_loss: 1.0813 - val_accuracy: 0.6617\n",
      "Epoch 29/30\n",
      "78584/78584 [==============================] - 14s 173us/sample - loss: 0.9220 - accuracy: 0.7090 - val_loss: 1.0778 - val_accuracy: 0.6627\n",
      "Epoch 30/30\n",
      "78584/78584 [==============================] - 13s 168us/sample - loss: 0.9209 - accuracy: 0.7096 - val_loss: 1.0732 - val_accuracy: 0.6620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model_mlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(GESTURE_TYPES, activation=None), \n",
    "    tf.keras.layers.Dense(256, activation=None), \n",
    "    tf.keras.layers.Activation('softmax')])\n",
    "model_mlp.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "history = model_mlp.fit(X, labels, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
